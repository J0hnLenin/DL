{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Лабораторная работа №3\n",
    "Классификация пингвинов\n",
    "Выполнили студенты Зимин Андрей Валерьевич, Жилин Андрей Игроевич"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.cluster.hierarchy import weighted\n",
    "\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.metrics import recall_score as rec\n",
    "from sklearn.metrics import precision_score as pre\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import qrcode\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import string\n",
    "from typing import Callable, List, Union\n",
    "from numpy.typing import NDArray\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.metrics import recall_score as rec\n",
    "from sklearn.metrics import precision_score as pre\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Задание 1\n",
    "1. Загрузить данные из файла «pinguins.csv». Проверить, что загружены все 333 кортежа данных по всем 7 признакам  \n",
    "2. Определить типы данных\n",
    "3. Определить параметры числовых данных\n",
    "4. Для нечисловых (текстовых) данных определить количество записей по каждому элементу и визуализировать гистограммы, например, так (для признака «species»)\n",
    "5. Для каждого текстового признака построить мозаику 2D диаграмм рассеяния выбирая в качестве параметров всевозможные пары числовых признаков, аналогично мозаике диаграмм для ирисов."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Загрузить данные из файла «pinguins.csv». Проверить, что загружены все 333 кортежа данных по всем 7 признакам"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = pd.read_csv(\"./data/penguins.csv\")\n",
    "df"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Загрузили датасет. Действительно 7 признаков и 333 строки"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Определить типы данных"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df.info()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "species            - категориальный признак  \n",
    "island             - категориальный признак  \n",
    "bill_length_mm     - числовой признак  \n",
    "bill_depth_mm      - числовой признак  \n",
    "flipper_length_mm  - числовой признак  \n",
    "body_mass_g        - числовой признак  \n",
    "sex                - бинарный признак   "
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Перед обучением нужно будет закодировать категориальные признаки one-hot encoding"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Определить параметры числовых данных"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "df.describe()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Видим, что сильно выделяется признак массы тела, он на 2-3 порядка больше остальных признаков. Перед обучением было бы неплохо провести нормализацию"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4. Для нечисловых (текстовых) данных определить количество записей по каждому элементу и визуализировать гистограммы, например, так (для признака «species»)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "category_columns = ['species', 'island', 'sex']\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "\n",
    "for i, category in enumerate(category_columns):\n",
    "    sns.countplot(data=df, x=category, ax=ax[i])\n",
    "    ax[i].set_title(f'Признак {category}')\n",
    "    ax[i].set_ylabel('Количество')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5. Для каждого текстового признака построить мозаику 2D диаграмм рассеяния выбирая в качестве параметров всевозможные пары числовых признаков, аналогично мозаике диаграмм для ирисов."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pairplot = sns.pairplot(df, hue='species')\n",
    "pairplot.fig.suptitle('Парные графики пингвинов по признаку вида', y=1.02)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Пингвинов хорошо получиться классифицировать по признаку пола\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ax[i].set_ylabel('Количество')\n",
    "palette = {'male': 'blue', 'female': 'red'}\n",
    "pairplot = sns.pairplot(df, hue='sex', palette=palette, )\n",
    "pairplot.fig.suptitle('Парные графики пингвинов по признаку пола', y=1.02)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Судя по графикам удастся хорошо классифицировать пингвинов по классам."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pairplot = sns.pairplot(df, hue='island')\n",
    "pairplot.fig.suptitle('Парные графики пингвинов по признаку острова', y=1.02)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Видно, что пингвины с одними и теми же массо-габаритными характеристиками живут на разных островах. Классифицировать по этому признаку будет трудно."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Реализация Персептрона и других вспомогательных функций"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Perceptron:\n",
    "  def __init__(self, hidden_layers : List[int],\n",
    "               activations: List[Callable],\n",
    "               eta:Union[int, float] = 1,\n",
    "               n_epochs: int = 100,\n",
    "               random_weights=None,\n",
    "               random_state=None):\n",
    "    np.random.seed(random_state)\n",
    "    random.seed(random_state)\n",
    "    self.is_fitted = False\n",
    "    self.layers = []\n",
    "    self.epochs = n_epochs\n",
    "    self.eta = eta\n",
    "    self.errors = []\n",
    "    l = hidden_layers + [1]\n",
    "    for i in range(len(hidden_layers)):\n",
    "      self.layers.append(Layer((l[i]+1, l[i+1]), activations[i], i + 1, random_weights=random_weights))\n",
    "\n",
    "  @staticmethod\n",
    "  def relu(x):\n",
    "      return np.maximum(0, x)\n",
    "  @staticmethod\n",
    "  def step(x):\n",
    "      return (x >= 0).astype(np.float64)\n",
    "\n",
    "  @staticmethod\n",
    "  def sigmoid(x):\n",
    "    return np.where(x >= 0,\n",
    "                   1 / (1 + np.exp(-x)),\n",
    "                   np.exp(x) / (1 + np.exp(x)))\n",
    "\n",
    "  @staticmethod\n",
    "  def shuffle(X, y):\n",
    "    n = len(y)\n",
    "    a = [(random.random(), X[i, :], y[i]) for i in range(n)]\n",
    "    a.sort()\n",
    "    new_X = np.array([a[i][1] for i in range(n)])\n",
    "    new_y = np.array([a[i][2] for i in range(n)])\n",
    "    return new_X, new_y\n",
    "\n",
    "  @staticmethod\n",
    "  def get_grad(activation):\n",
    "      activation = activation.pyfunc\n",
    "      if activation == Perceptron.sigmoid:\n",
    "          s = Perceptron.sigmoid\n",
    "          return lambda x: s(x) * (1 - s(x))\n",
    "      return lambda x: (x >= 0).astype(np.int64)\n",
    "\n",
    "\n",
    "  def predict(self, train_sample: NDArray, logging: bool = False) -> NDArray:\n",
    "    result = np.zeros(train_sample.shape[0])\n",
    "    for i in range(train_sample.shape[0]):\n",
    "      x = train_sample[i, :]\n",
    "      for layer in self.layers:\n",
    "        x = np.append(x, values=[1]) # добавление свободного коэффициента\n",
    "        x = layer.forward(x, logging)\n",
    "\n",
    "      result[i] = x[0]\n",
    "      if logging:\n",
    "        print(result[i])\n",
    "    return result\n",
    "\n",
    "  def train(self, train_sample: NDArray,\n",
    "          train_ans: NDArray,\n",
    "          batch_size: int = 32,  # Размер пакета (можно менять)\n",
    "          logging=False,\n",
    "          activation=np.sign,\n",
    "          random_weights=None) -> list[float]:\n",
    "    if not self.is_fitted:\n",
    "        self.layers = [Layer((train_sample.shape[1]+1,\n",
    "                            self.layers[0].size[0]-1),\n",
    "                            activation,\n",
    "                            0,\n",
    "                            random_weights=random_weights)] + self.layers\n",
    "        self.is_fitted = True\n",
    "\n",
    "    n_samples = train_sample.shape[0]\n",
    "    for epoch in range(self.epochs):\n",
    "        train_sample, train_ans = Perceptron.shuffle(train_sample, train_ans)\n",
    "        error = 0\n",
    "\n",
    "        # Разбиваем данные на пакеты\n",
    "        for batch_start in range(0, n_samples, batch_size):\n",
    "            batch_end = min(batch_start + batch_size, n_samples)\n",
    "            batch_X = train_sample[batch_start:batch_end, :]\n",
    "            batch_y = train_ans[batch_start:batch_end]\n",
    "\n",
    "            # Инициализируем накопители градиентов для каждого слоя\n",
    "            weight_updates = [np.zeros_like(layer.w) for layer in self.layers]\n",
    "            batch_error = 0\n",
    "\n",
    "            # Обрабатываем каждый пример в пакете\n",
    "            for i in range(batch_X.shape[0]):\n",
    "                x = batch_X[i, :]\n",
    "                target = batch_y[i]\n",
    "\n",
    "                # Прямое распространение (forward pass)\n",
    "                activations = [x]\n",
    "                for layer in self.layers:\n",
    "                    x = np.append(x, values=[1])\n",
    "                    x = layer.forward(x, logging)\n",
    "                    activations.append(x)\n",
    "\n",
    "                predicted = x[0]\n",
    "                delta = target - predicted\n",
    "                batch_error += abs(delta)\n",
    "\n",
    "                # Обратное распространение (backward pass)\n",
    "                delta_next = delta\n",
    "                for layer_idx in range(len(self.layers)-1, -1, -1):\n",
    "                    layer = self.layers[layer_idx]\n",
    "                    layer_input = activations[layer_idx]\n",
    "                    delta_next, weight_update = layer.backprop(delta_next, layer_input, self.eta)\n",
    "                    weight_updates[layer_idx] += weight_update  # Накопление градиентов\n",
    "\n",
    "            # Усредняем градиенты и обновляем веса\n",
    "            for layer, update in zip(self.layers, weight_updates):\n",
    "                layer.w += (self.eta / batch_size) * update  # Усреднённое обновление\n",
    "\n",
    "            error += batch_error\n",
    "\n",
    "        self.errors.append(error)\n",
    "    return self.errors\n",
    "\n",
    "\n",
    "class Layer:\n",
    "  def __init__(self,\n",
    "               size: tuple[int, int],\n",
    "               activation: Callable,\n",
    "               index: int,\n",
    "               value: Union[int, float]=0,\n",
    "               random_weights=None):\n",
    "    self.size = size\n",
    "    self.w = np.full(size, value, dtype=np.float64)\n",
    "    if random_weights is not None:\n",
    "      self.w = np.random.uniform(random_weights[0], random_weights[1], self.size)\n",
    "    self.activation = np.vectorize(activation)\n",
    "    self.i = index\n",
    "    self.last_result = np.array([])\n",
    "    self.last_x = np.array([])\n",
    "    self.last_m = np.array([])\n",
    "\n",
    "  def backward(self, value) -> None:\n",
    "    if value > 0:\n",
    "      # надо увеличить те веса, где нет активации,\n",
    "      # но должна быть активация\n",
    "      d = (self.last_x>0)*value\n",
    "      d = np.repeat(np.array([d]).T, self.w.shape[1], axis=1)\n",
    "      self.w = self.w + d\n",
    "    if value < 0:\n",
    "      # надо уменьшить те веса,\n",
    "      # где активации быть не должно\n",
    "      d = (self.last_x>0)*value\n",
    "      d = np.repeat(np.array([d]).T, self.w.shape[1], axis=1)\n",
    "      self.w = self.w + d\n",
    "  def backprop(self, delta_prev, layer_input, eta):\n",
    "    # Получаем взвешенную сумму (последний расчёт в forward)\n",
    "    m = self.last_m\n",
    "\n",
    "    # Вычисляем производную активационной функции\n",
    "    grad = Perceptron.get_grad(self.activation)(m)\n",
    "\n",
    "    # delta для текущего слоя = delta_prev * производная активации\n",
    "    delta = delta_prev * grad\n",
    "\n",
    "    # Добавляем bias-единицу к входному вектору (если её ещё нет)\n",
    "    layer_input_with_bias = np.append(layer_input, 1)\n",
    "\n",
    "    # Возвращаем ошибку для предыдущего слоя (без учёта bias-весов)\n",
    "    delta_next = delta @ self.w[:-1].T\n",
    "\n",
    "    # Возвращаем градиент для накопления (без обновления весов)\n",
    "    weight_update = np.outer(layer_input_with_bias, delta)\n",
    "\n",
    "    return delta_next, weight_update\n",
    "\n",
    "  def forward(self, x, logging) -> NDArray:\n",
    "    if logging:\n",
    "      print(f\"Слой №{self.i+1}\")\n",
    "      print(f\"Сенсоры  : {x}\")\n",
    "      print(f\"Размер: {self.size}\")\n",
    "\n",
    "    m = np.dot(x, self.w)\n",
    "    result = self.activation(m)\n",
    "    self.last_result = result\n",
    "    self.last_x = x\n",
    "    self.last_m = m\n",
    "    if logging:\n",
    "      print(f\"Сумматор : {m}\")\n",
    "      print(f\"Активация: {result}\")\n",
    "      print(f\"Результат размера {result.shape}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "def count_metrics(predicted : NDArray[bool], real: NDArray[bool], label='') -> None:\n",
    "    print(f'{label}: ')\n",
    "    print('Accuracy: ', acc(predicted, real))\n",
    "    print('Recall: ', rec(predicted, real))\n",
    "    print('Precision: ', pre(predicted, real))\n",
    "\n",
    "\n",
    "def get_features(data, target, target_name, features) -> (NDArray, NDArray):\n",
    "\n",
    "    data = data[features + [target]]\n",
    "    data.loc[:, target] = (data[target] == target_name)\n",
    "    data_y = data[[target]].to_numpy().reshape(1, -1)[0] * 1\n",
    "    data_x = data[features].to_numpy()\n",
    "\n",
    "    return data_x, data_y\n",
    "\n",
    "\n",
    "def build_errors(errors: list[float], perceptron: Perceptron) -> None:\n",
    "    ax = plt.figure().gca()\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    plt.plot(list(range(len(errors))), errors, marker='o', linestyle='dashed')\n",
    "\n",
    "    plt.xlabel(\"Эпохи\")\n",
    "    plt.ylabel(\"Количество ошибок за эпоху\")\n",
    "    plt.title(\"Обучение нейросети\\nбинарной классификации на числовых признаках\")\n",
    "    print(\"Размерность слоёв: \", *[i.size for i in  perceptron.layers])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def print_contour(model, X, y, main_1=0, main_2=1, supp=None, columns_num=None, label = ''):\n",
    "    # 1. Генерируем сетку для 2-х выбранных признаков\n",
    "    if supp is None:\n",
    "        supp = [2, 3]\n",
    "    if columns_num is None:\n",
    "        columns_num = [''] * 2\n",
    "    x_min, x_max = X[:, main_1].min() - 1, X[:, main_1].max() + 1\n",
    "    y_min, y_max = X[:, main_2].min() - 1, X[:, main_2].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "    # 2. Создаём массив точек в 4-х мерном пространстве, но только для выбранных 2-х признаков\n",
    "    mean_vals = np.mean(X, axis=0)  # Средние значения для всех 4-х признаков\n",
    "    fixed_features = mean_vals[supp]  # Средние значения для 3-го и 4-го признаков\n",
    "\n",
    "    grid_points_4d = np.zeros((xx.ravel().shape[0], 2+len(supp)))\n",
    "    grid_points_4d[:, [main_1, main_2]] = np.column_stack((xx.ravel(), yy.ravel()))  # 2 выбранных признака\n",
    "    grid_points_4d[:, [supp]] = fixed_features  # Остальные 2 признака - средние значения\n",
    "\n",
    "    # 3. Предсказываем классы для сеточных точек в 4-х мерном пространстве\n",
    "    Z = model.predict(grid_points_4d)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # 4. Визуализация\n",
    "    plt.contourf(xx, yy, Z, alpha=0.8, cmap='coolwarm')\n",
    "    plt.contour(xx, yy, Z, colors=['k', 'k', 'k'], linestyles=['--', '-', '--'], linewidths=[1, 2, 1])\n",
    "\n",
    "    # Отображаем точки данных\n",
    "    plt.scatter(X[:, main_1], X[:, main_2], c=y, cmap='coolwarm', edgecolor='k')\n",
    "    plt.xlabel(columns_num[main_1])\n",
    "    plt.ylabel(columns_num[main_2])\n",
    "    plt.title(f'Проекция линий уровня персептрона на 2D {label}')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def count_metrics(predicted : NDArray[bool], real: NDArray[bool], label='') -> None:\n",
    "    print(f'{label}: ')\n",
    "    print('Accuracy: ', acc(predicted, real))\n",
    "    print('Recall: ', rec(predicted, real))\n",
    "    print('Precision: ', pre(predicted, real))\n",
    "\n",
    "\n",
    "def get_features(data, target, target_name, features) -> (NDArray, NDArray):\n",
    "\n",
    "    data = data[features + [target]]\n",
    "    data.loc[:, target] = (data[target] == target_name)\n",
    "    data_y = data[[target]].to_numpy().reshape(1, -1)[0] * 1\n",
    "    data_x = data[features].to_numpy()\n",
    "\n",
    "    return data_x, data_y\n",
    "\n",
    "\n",
    "def build_errors(errors: list[float], perceptron: Perceptron) -> None:\n",
    "    ax = plt.figure().gca()\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    plt.plot(list(range(len(errors))), errors, marker='o', linestyle='dashed')\n",
    "\n",
    "    plt.xlabel(\"Эпохи\")\n",
    "    plt.ylabel(\"Количество ошибок за эпоху\")\n",
    "    plt.title(\"Обучение нейросети\\nбинарной классификации на числовых признаках\")\n",
    "    print(\"Размерность слоёв: \", *[i.size for i in  perceptron.layers])\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Задание 2\n",
    "1. Используя персептрон, постройте бинарный классификатор для определения пола пингвина на основе только числовых признаков. Оцените качество работы классификатора.\n",
    "\n",
    "2. Постройте 3 классификатора для определения пола пингвина на основе числовых признаков для каждого из видов пингвинов. Оцените их качество. Сравните точности классификаторов между собой и с классификатором п.2.1.\n",
    "\n",
    "3. Попробуйте каждый из 3-х классификаторов п.2.2 проверить на всей выборке (т.е. на пингвинах разных видов)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Используя персептрон, постройте бинарный классификатор для определения пола пингвина на основе только числовых признаков. Оцените качество работы классификатора."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Создаим список числовых признаков"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "numeric_features = ['bill_length_mm', 'bill_depth_mm', 'body_mass_g', 'flipper_length_mm']\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X, y = get_features(df, 'sex', 'male', numeric_features) #используем функцию для получения необходмых признаков\n",
    "\n",
    "scaler = StandardScaler() #Стандартизация\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=19) # Разбиение в соответствии с замечанием\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "X_train"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "y_train.sum()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "MLP = Perceptron([300], [lambda x: Perceptron.relu(x).astype(np.int64)], n_epochs=200, random_state=13, eta=0.0001) #Иницализируем персептрон да поинтереснее\n",
    "errors = MLP.train(np.array(X_train, dtype=np.float64), np.array(y_train, dtype=np.float64) , logging=False, activation=Perceptron.sigmoid, batch_size=50, random_weights=[-3, 3])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "MLP.predict(np.array(X_test, dtype=np.float64))"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Наблюдаем неравномерную сходимость к минимуму ошибок"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "build_errors(errors, MLP)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Визуально видим как неплохо получилось у персептрона на срезе отделить два признака"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print_contour(MLP, X, y, 0, 1, [2, 3], numeric_features, 'только числовые признаки и бинарная классификация')"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "y_test_pred = np.array(MLP.predict(X_test)) == 1\n",
    "y_train_pred = np.array(MLP.predict(X_train)) == 1\n",
    "\n",
    "count_metrics(y_train_pred, y_train == 1, 'Обучающая выборка')\n",
    "count_metrics(y_test_pred,  y_test == 1, 'Тестовая выборка')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Естественно метрика на обучающей выборке 1 так как мы сошлись к минимуму ошибки, а на тестовой метрика ниже, нельзя сказать что значительно ниже, но и незначительной эту разницу не назовешь"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Постройте 3 классификатора для определения пола пингвина на основе числовых признаков для каждого из видов пингвинов. Оцените их качество. Сравните точности классификаторов между собой и с классификатором п.2.1."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df[df['species'] == 'Adelie'] #смотрим что там вообще лежит"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_features(data, target, target_name, features):\n",
    "\n",
    "    data = data[features + [target]]\n",
    "    data.loc[:, target] = (data[target] == target_name)\n",
    "    data_y = data[[target]].to_numpy().reshape(1, -1)[0] * 1\n",
    "    data_x = data[numeric_features].to_numpy()\n",
    "\n",
    "    return data_x, data_y\n",
    "\n",
    "\n",
    "X1, y1, = get_features(df[df['species'] == 'Adelie'], 'sex', 'male', numeric_features) #получаем для всех признаков выборку(можно было здесь в форе но не принципиально)\n",
    "X2, y2 = get_features(df[df['species'] == 'Gentoo'], 'sex', 'male', numeric_features)\n",
    "X3, y3 = get_features(df[df['species'] == 'Chinstrap'], 'sex', 'male', numeric_features)\n",
    "\n",
    "scaler1 = StandardScaler()\n",
    "scaler2 = StandardScaler()\n",
    "scaler3 = StandardScaler()\n",
    "#стандартизация для всех признаков\n",
    "species = ['Adelie', 'Gentoo', 'Chinstrap']\n",
    "\n",
    "X1 = scaler1.fit_transform(X1)\n",
    "X2 = scaler2.fit_transform(X2)\n",
    "X3 = scaler3.fit_transform(X3)\n",
    "scalers = [scaler1, scaler2, scaler3]\n",
    "datas = [X1, X2, X3]\n",
    "targets = [y1, y2, y3]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "X_train"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "тут уже в форе обучаем персептроны для каждого вида отдельно"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "percps = []\n",
    "\n",
    "X_trains = []\n",
    "X_tests = []\n",
    "y_trains = []\n",
    "y_tests = []\n",
    "#теперь уже в форе обучаем персептроны\n",
    "for i in range(len(datas)):\n",
    "    X_local_train, X_local_test, y_local_train, y_local_test = train_test_split(datas[i], targets[i], test_size=0.3, random_state=19)\n",
    "    percps.append(Perceptron([50], [Perceptron.step], n_epochs=100, random_state=13))\n",
    "    X_trains.append(X_local_train)\n",
    "    X_tests.append(X_local_test)\n",
    "    y_trains.append(y_local_train)\n",
    "    y_tests.append(y_local_test)\n",
    "    errors = percps[i].train(X_local_train, y_local_train , logging=False, activation=Perceptron.step, random_weights=[-100, 100])\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "считаем метрики для каждого классификатора"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for i in range(len(datas)):\n",
    "    y_train_pred = np.array(percps[i].predict(X_trains[i])) == 1\n",
    "    y_test_pred = np.array(percps[i].predict(X_tests[i])) == 1\n",
    "\n",
    "    y_train = y_trains[i] == 1\n",
    "    y_test  = y_tests[i] == 1\n",
    "    count_metrics(y_train, y_train_pred, f'Обучающая выборка {species[i]}')\n",
    "    count_metrics(y_test, y_test_pred, f'Тестовая выборка {species[i]}')\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "В графики добавлю только вид пингвина так как задача та же бинарная классификация"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "build_errors(errors, percps[0], species[0])"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "build_errors(errors, percps[1], species[0])"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "build_errors(errors, percps[2], species[0])"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print_contour(percps[0], X_trains[0], y_trains[0], 0, 1, [2, 3], numeric_features, species[0])"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print_contour(percps[1], X_trains[1], y_trains[1], 0, 1, [2, 3], numeric_features, species[0])"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print_contour(percps[-1], X_trains[-1], y_trains[-1], 0, 1, [2, 3], numeric_features, species[0])"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Понятно что по видам персептрону было проще разделить так как все эти параметры напрямую зависят от вида"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Попробуйте каждый из 3-х классификаторов п.2.2 проверить на всей выборке (т.е. на пингвинах разных видов)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for i in range(3):\n",
    "    x_val, y_val = get_features(df, 'sex', 'male', numeric_features)\n",
    "    x_val = scalers[i].transform(x_val)\n",
    "    y_val_pred = percps[i].predict(x_val)\n",
    "\n",
    "    count_metrics(y_val_pred == 1, y_val == 1, 'По всему')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "На общей выборке метрики несильно отличаются друг от друга, так как сильно подогнались под виды"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Задание 3\n",
    " Бинарная классификация с использованием ADALINE.\n",
    "1. Повторите пп.1-3 предыдущего задания, построив классификатор на основе адаптивного нейрона.\n",
    "\n",
    "2. Включите в список признаков вид пингвина, представив его числом (1,2,3) для разных видов. Оцените качество классификации и сравните с результатом пункта 3.1.\n",
    "\n",
    "3. Замените признак вид на три бинарных признака Adelie, Chinstrap, Gentoo, в каждом из которых значение 1 соответствует тому, что данный пингвин принадлежит соответствующему виду:\n",
    "\n",
    "4. Выполните классификацию по полу, используя уже 7 числовых признаков. Сравните качество классификации с предыдущими вариантами.\n",
    "\n",
    "5. Выполните классификацию по каждому из видов пингвина, используя 5 числовых признаков (4 размера-веса и пол: 1-male, 0-female). Сравните качество классификаторов.\n",
    "\n",
    "6. Повторите предыдущий пункт, добавив к 5 числовым признакам ещё три бинарных, представляющих принадлежность к тому или иному острову.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Повторите пп.1-3 предыдущего задания, построив классификатор на основе адаптивного нейрона."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Просто повторяем задание 2 полностью но персептрон используем тот же"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "X, y = get_features(df, 'sex', 'male', numeric_features)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=19)\n",
    "\n",
    "adaline = Perceptron([1000], [Perceptron.step], n_epochs=50, random_state=13)\n",
    "errors = adaline.train(X_train, y_train, logging=False, activation=Perceptron.step, random_weights=[-100, 100])\n",
    "\n",
    "build_errors(errors, adaline)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print_contour(adaline, X, y, 0, 1, [2, 3], numeric_features)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "copy_df = df.copy()\n",
    "\n",
    "X1, y1, = get_features(copy_df[copy_df['species'] == 'Adelie'], 'sex', 'male', numeric_features)\n",
    "X2, y2 = get_features(copy_df[copy_df['species'] == 'Gentoo'], 'sex', 'male', numeric_features)\n",
    "X3, y3 = get_features(copy_df[copy_df['species'] == 'Chinstrap'], 'sex', 'male', numeric_features)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X1 = scaler.fit_transform(X1)\n",
    "X2 = scaler.transform(X2)\n",
    "X3 = scaler.transform(X3)\n",
    "\n",
    "datas = [X1, X2, X3]\n",
    "targets = [y1, y2, y3]\n",
    "\n",
    "\n",
    "X_trains = []\n",
    "X_tests = []\n",
    "y_trains = []\n",
    "y_tests = []\n",
    "for i in range(len(datas)):\n",
    "    X_local_train, X_local_test, y_local_train, y_local_test = train_test_split(datas[i], targets[i], test_size=0.3,\n",
    "                                                                                random_state=19)\n",
    "    percps.append(Perceptron([50], [Perceptron.step], n_epochs=100, random_state=13))\n",
    "    X_trains.append(X_local_train)\n",
    "    X_tests.append(X_local_test)\n",
    "    y_trains.append(y_local_train)\n",
    "    y_tests.append(y_local_test)\n",
    "    errors = adaline.train(X_local_train, y_local_train, logging=False, activation=Perceptron.step,\n",
    "                             random_weights=[-100, 100])\n",
    "\n",
    "for i in range(len(datas)):\n",
    "    y_train_pred = np.array(adaline.predict(X_trains[i])) == 1\n",
    "    y_test_pred = np.array(adaline.predict(X_tests[i])) == 1\n",
    "\n",
    "    y_train = y_trains[i] == 1\n",
    "    y_test = y_tests[i] == 1\n",
    "\n",
    "    count_metrics(y_train_pred, y_train, 'Обучающая')\n",
    "    count_metrics(y_test_pred, y_test, 'Тестовая')\n",
    "X, y = get_features(copy_df, 'sex', 'male', numeric_features)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "\n",
    "y_test_pred = adaline.predict(X) == 1\n",
    "y_test = y == 1\n",
    "count_metrics(y_test_pred, y_test, 'ALL_X')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "build_errors(errors, adaline, 'дообученная на разных выборках')"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print_contour(adaline, X, y, 0, 1, [2, 3], numeric_features, 'дообученный на разных выборках')"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "После повторения всех шагов без комментариев так как они есть в предыдущем пункте, мы получили метрику значительно хуже чем в персептроне неадаптивном, то есть лучше не дообучать пока нет обратного распротсранения ошибки через градиенты"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Включите в список признаков вид пингвина, представив его числом (1,2,3) для разных видов. Оцените качество классификации и сравните с результатом пункта 3.1."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_features(data, target, target_name, features) -> (NDArray, NDArray):\n",
    "\n",
    "    data = data[features + [target]]\n",
    "    data.loc[:, target] = (data[target] == target_name)\n",
    "    data_y = data[[target]].to_numpy().reshape(1, -1)[0] * 1\n",
    "    data_x = data[features].to_numpy()\n",
    "\n",
    "    return data_x, data_y\n",
    "\n",
    "adaline_cat = Perceptron([1000], [Perceptron.step], n_epochs=100, random_state=13, eta=0.001)\n",
    "new_features = numeric_features + ['species']\n",
    "copy_df = df.copy()\n",
    "\n",
    "labelEncoder = LabelEncoder()\n",
    "scaler = StandardScaler()\n",
    "copy_df['species'] = labelEncoder.fit_transform(copy_df['species']) + 1\n",
    "X, y = get_features(copy_df, 'sex', 'male', numeric_features + ['species'])\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=19)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "errors = adaline_cat.train(X_train, y_train, logging=False, activation=Perceptron.step, random_weights=[-100, 100])"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "X_train"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "y_train_pred = np.array(adaline_cat.predict(X_train)) == 1\n",
    "y_test_pred = np.array(adaline_cat.predict(X_test)) == 1\n",
    "y_train = y_train == 1\n",
    "y_test = y_test == 1\n",
    "count_metrics(y_train_pred, y_train, 'Обучающая выборка')\n",
    "count_metrics(y_test_pred, y_test, 'Тестовая выборка')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Метрика получилась почти такая же как и на без вида, скорее всего потому что мы использовали вид как число"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "build_errors(errors, adaline_cat)\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print_contour(adaline_cat, X, y, 0, 1, [2, 3, 4], new_features)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3 Замените признак вид на три бинарных признака Adelie, Chinstrap, Gentoo, в каждом из которых значение 1 соответствует тому, что данный пингвин принадлежит соответствующему виду:\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "adaline_one_hot = Perceptron([1000], [Perceptron.step], n_epochs=100, random_state=13)\n",
    "new_features = numeric_features + ['species']\n",
    "\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "ohe.set_output(transform='pandas')\n",
    "copy_df = df.copy()\n",
    "\n",
    "\n",
    "df_species = ohe.fit_transform(df[['species']].to_numpy())\n",
    "\n",
    "copy_df = pd.concat([copy_df[numeric_features], df_species], axis=1)\n",
    "copy_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "temp_df = pd.concat([copy_df, df[['sex']]], axis=1)\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Разбиваем на выборки тестовую и обучающую"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "X, y = get_features( temp_df, 'sex', 'male', numeric_features + list(ohe.get_feature_names_out()))\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=19)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4. Выполните классификацию по полу, используя уже 7 числовых признаков. Сравните качество классификации с предыдущими вариантами."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "X_train #смотрим что тут есть"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "errors = adaline_one_hot.train(X_train, y_train, logging=False, activation=Perceptron.step, random_weights=[-100, 100])\n",
    "y_train_pred = np.array(adaline_one_hot.predict(X_train)) == 1\n",
    "y_test_pred = np.array(adaline_one_hot.predict(X_test)) == 1\n",
    "y_train = y_train == 1\n",
    "y_test = y_test == 1\n",
    "count_metrics(y_train_pred, y_train, 'Обучающая выборка')\n",
    "count_metrics(y_test_pred, y_test, 'Тестовая выборка')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Видим что метрика улучшилась на тестовой но не сильно можно списать это на везение при разбиении хотя использовали тот же random_state"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "build_errors(errors, adaline_one_hot)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print_contour(adaline_one_hot, X, y, 0, 1, [2, 3, 4, 5, 6], new_features)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5. Выполните классификацию по каждому из видов пингвина, используя 5 числовых признаков (4 размера-веса и пол: 1-male, 0-female). Сравните качество классификаторов."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "copy_df['sex'] = (df['sex'] == 'male').apply(float)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "copy_df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_adelie, y_adelie = get_features(copy_df, 'x0_Adelie', True, numeric_features + ['sex'])\n",
    "X_chinstrap, y_chinstrap = get_features(copy_df, 'x0_Chinstrap', True, numeric_features + ['sex'])\n",
    "X_gentoo, y_gentoo = get_features(copy_df, 'x0_Gentoo', True, numeric_features + ['sex'])\n",
    "scaler = StandardScaler()\n",
    "X_adelie = scaler.fit_transform(X_adelie)\n",
    "X_chinstrap = scaler.transform(X_chinstrap)\n",
    "X_gentoo = scaler.transform(X_gentoo)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "X_adelie"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_penguins = [X_adelie, X_chinstrap, X_gentoo]\n",
    "y_penguins = [y_adelie, y_chinstrap, y_gentoo]\n",
    "X_trains = []\n",
    "X_tests = []\n",
    "y_trains = []\n",
    "y_tests = []\n",
    "percps_pen = []\n",
    "for i in range(len(datas)):\n",
    "    X_local_train, X_local_test, y_local_train, y_local_test = train_test_split(X_penguins[i], y_penguins[i], test_size=0.3,\n",
    "                                                                                random_state=19)\n",
    "    percps_pen.append(Perceptron([50], [Perceptron.step], n_epochs=100, random_state=13))\n",
    "    X_trains.append(X_local_train)\n",
    "    X_tests.append(X_local_test)\n",
    "    y_trains.append(y_local_train)\n",
    "    y_tests.append(y_local_test)\n",
    "    errors = percps_pen[i].train(X_local_train, y_local_train, logging=False, activation=Perceptron.step,\n",
    "                             random_weights=[-100, 100])\n",
    "\n",
    "for i in range(len(datas)):\n",
    "    y_train_pred = np.array(percps_pen[i].predict(X_trains[i])) == 1\n",
    "    y_test_pred = np.array(percps_pen[i].predict(X_tests[i])) == 1\n",
    "\n",
    "    y_train = y_trains[i] == 1\n",
    "    y_test = y_tests[i] == 1\n",
    "\n",
    "    count_metrics(y_train_pred, y_train, 'Обучающая')\n",
    "    count_metrics(y_test_pred, y_test, 'Тестовая')\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "build_errors(errors, percps_pen[0], species[0])"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "build_errors(errors, percps_pen[1], species[1])"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "build_errors(errors, percps_pen[2], species[2])"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Все сети сошлись на первой эпохе, очень удивительно пять раз проверил вроде таргет не закинули в обучающую"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print_contour(percps_pen[0], X_penguins[0], y_penguins[0], 0, 1, [2, 3, 4], new_features, species[0])"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print_contour(percps_pen[1], X_penguins[1], y_penguins[1], 0, 1, [2, 3, 4], new_features, species[1])"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print_contour(percps_pen[2], X_penguins[2], y_penguins[2], 0, 1, [2, 3, 4], new_features, species[2])"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Плюсом по графикам видно что он справился с разделением"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6. Повторите предыдущий пункт, добавив к 5 числовым признакам ещё три бинарных, представляющих принадлежность к тому или иному острову."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ohe_islands = OneHotEncoder(sparse_output=False)\n",
    "ohe.set_output(transform='pandas')\n",
    "df_islands = ohe.fit_transform(df[['island']].to_numpy())\n",
    "\n",
    "copy_df = pd.concat([copy_df, df_islands], axis=1)\n",
    "copy_df\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_adelie, y_adelie = get_features(copy_df, 'x0_Adelie', True, numeric_features + ['sex'] + ['x0_Biscoe', 'x0_Dream', 'x0_Torgersen'])\n",
    "X_chinstrap, y_chinstrap = get_features(copy_df, 'x0_Chinstrap', True, numeric_features + ['sex'] + ['x0_Biscoe', 'x0_Dream', 'x0_Torgersen'])\n",
    "X_gentoo, y_gentoo = get_features(copy_df, 'x0_Gentoo', True, numeric_features + ['sex'] + ['x0_Biscoe', 'x0_Dream', 'x0_Torgersen'])\n",
    "scaler = StandardScaler()\n",
    "X_adelie = scaler.fit_transform(X_adelie)\n",
    "X_chinstrap = scaler.transform(X_chinstrap)\n",
    "X_gentoo = scaler.transform(X_gentoo)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "X_adelie #смотрим что внутри"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_penguins = [X_adelie, X_chinstrap, X_gentoo]\n",
    "y_penguins = [y_adelie, y_chinstrap, y_gentoo]\n",
    "X_trains = []\n",
    "X_tests = []\n",
    "y_trains = []\n",
    "y_tests = []\n",
    "percps_pen = []\n",
    "for i in range(len(datas)):\n",
    "    X_local_train, X_local_test, y_local_train, y_local_test = train_test_split(X_penguins[i], y_penguins[i], test_size=0.3,\n",
    "                                                                                random_state=19)\n",
    "    percps_pen.append(Perceptron([50], [Perceptron.step], n_epochs=100, random_state=13))\n",
    "    X_trains.append(X_local_train)\n",
    "    X_tests.append(X_local_test)\n",
    "    y_trains.append(y_local_train)\n",
    "    y_tests.append(y_local_test)\n",
    "    errors = percps_pen[i].train(X_local_train, y_local_train, logging=False, activation=Perceptron.step,\n",
    "                             random_weights=[-100, 100])\n",
    "\n",
    "for i in range(len(datas)):\n",
    "    y_train_pred = np.array(percps_pen[i].predict(X_trains[i])) == 1\n",
    "    y_test_pred = np.array(percps_pen[i].predict(X_tests[i])) == 1\n",
    "\n",
    "    y_train = y_trains[i] == 1\n",
    "    y_test = y_tests[i] == 1\n",
    "\n",
    "    count_metrics(y_train_pred, y_train, 'Обучающая')\n",
    "    count_metrics(y_test_pred, y_test, 'Тестовая')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "build_errors(errors, percps_pen[0], species[0])"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "build_errors(errors, percps_pen[1], species[1])"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "build_errors(errors, percps_pen[2], species[2])"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print_contour(percps_pen[0], X_penguins[0], y_penguins[0], 0, 1, [2, 3, 4, 5, 6, 7], new_features, species[0])"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print_contour(percps_pen[1], X_penguins[1], y_penguins[1], 0, 1, [2, 3, 4, 5, 6, 7], new_features, species[1])"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print_contour(percps_pen[2], X_penguins[2], y_penguins[2], 0, 1, [2, 3, 4,5, 6, 7], new_features, species[2])"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Метрика не улучшилась по очевидным причинам лучше некуда, и не ухудшилась, получается остров лишнее для определение вида"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Задание 4\n",
    "Множественная классификация с использованием ADALINE\n",
    "1. Постройте сеть из 4 нейронов. На первом слое три из них определяют принадлежность к одному из трёх видов пингвинов. На втором слое на основе оценок 1-го слоя выносится суждение о том, какому из видов принадлежит конкретный объект. Нейрон этого слоя тоже надо обучить.\n",
    "Провести расчёты в трёх вариантах:\n",
    "2. используя 4 числовых слоя (только размеры-веса)\n",
    "3. используя 5 числовых слоёв (+пол)\n",
    "4. используя 8 числовых слоёв (+остров).\n",
    "5. Оценить качество полученных классификаторов. Сделать вывод.\n",
    "\n",
    "Оценка за работу 5 баллов. Мало(\n",
    "Дополнительные 2 балла могут быть выставлены, если обучение каждого классификатора сопровождается выводом графика динамики качества обучения по эпохам и диаграммы классификации областей (оси – два числовых признака размер/вес на выбор студента)\n",
    "Дополнительный 1 балл за вывод перед каждым обучением информации о характере обучения и первых 5-ти строк обучающей выборки.\n",
    " Доп задания сделаны.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Постройте сеть из 4 нейронов. На первом слое три из них определяют принадлежность к одному из трёх видов пингвинов. На втором слое на основе оценок 1-го слоя выносится суждение о том, какому из видов принадлежит конкретный объект. Нейрон этого слоя тоже надо обучить."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. используя 4 числовых слоя (только размеры-веса)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "формируем выборку исходя из потребностей"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "copy_df = df.copy()\n",
    "\n",
    "new_features = numeric_features + ['species']\n",
    "copy_df = df.copy()\n",
    "\n",
    "labelEncoder = LabelEncoder()\n",
    "scaler = StandardScaler()\n",
    "copy_df['sex'] = (copy_df['sex'] == 'male').apply(float)\n",
    "copy_df['species'] = labelEncoder.fit_transform(copy_df['species'])\n",
    "X, _ = get_features(copy_df, 'species', 'Adelie', numeric_features )\n",
    "y = copy_df['species'].to_numpy().reshape(1, -1)[0] * 1\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=19)\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "X_train #убеждаемся в соответствии"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "MLP_targ = Perceptron([3], [lambda x: round(min(Perceptron.relu(x), 2))], n_epochs=200, random_state=16, eta=0.0001)\n",
    "errors = MLP_targ.train(X_train, y_train, logging=False, activation=Perceptron.relu,\n",
    "                             random_weights=[-1, 1])\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "build_errors(errors, MLP_targ)\n",
    "plt.ylim((1, 250))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print_contour(MLP_targ, X, y, 0, 1, [2, 3], new_features)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "MLP_targ.predict(X_train)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "acc(MLP_targ.predict(X_train), y_train)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "acc(MLP_targ.predict(X_test), y_test)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Метрики мягко говоря не очень, но хотя бы не наивный классификатор"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. используя 5 числовых слоёв (+пол)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "copy_df = df.copy()\n",
    "\n",
    "new_features = numeric_features + ['species']\n",
    "copy_df = df.copy()\n",
    "\n",
    "labelEncoder = LabelEncoder()\n",
    "scaler = StandardScaler()\n",
    "copy_df['sex'] = (copy_df['sex'] == 'male').apply(float)\n",
    "copy_df['species'] = labelEncoder.fit_transform(copy_df['species'])\n",
    "X, _ = get_features(copy_df, 'species', 'Adelie', numeric_features +['sex'])\n",
    "y = copy_df['species'].to_numpy().reshape(1, -1)[0] * 1\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=19)\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "X_train #убеждаемся в том что пол появился"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "MLP_targ = Perceptron([3], [lambda x: round(min(Perceptron.relu(x), 2))], n_epochs=200, random_state=16, eta=0.0001)\n",
    "errors = MLP_targ.train(X_train, y_train, logging=False, activation=Perceptron.relu,\n",
    "                        random_weights=[-1, 1])\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "build_errors(errors, MLP_targ, 'Многоклассовой классификации')"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print_contour(MLP_targ, X, y, 0, 1, [2, 3, 4], new_features, 'Многоклассивоая классификация')"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "acc(MLP_targ.predict(X_train), y_train)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "acc(MLP_targ.predict(X_test), y_test)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Сейчас метрики получились ВО! Мы ничего не делали кроме как стандартизировали данные и придумали классную функцию активиации для классификатора остальное за нас сделал персептрон"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4. используя 8 числовых слоёв (+остров)."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "copy_df = df.copy()\n",
    "\n",
    "new_features = numeric_features + ['species']\n",
    "copy_df = df.copy()\n",
    "\n",
    "labelEncoder = LabelEncoder()\n",
    "scaler = StandardScaler()\n",
    "copy_df['sex'] = (copy_df['sex'] == 'male').apply(float)\n",
    "\n",
    "\n",
    "df_islands = ohe.fit_transform(df[['island']].to_numpy())\n",
    "\n",
    "copy_df = pd.concat([copy_df, df_islands], axis=1)\n",
    "\n",
    "copy_df['species'] = labelEncoder.fit_transform(copy_df['species'])\n",
    "X, _ = get_features(copy_df, 'species', 'Adelie', numeric_features +['sex'] + ['x0_Biscoe', 'x0_Dream', 'x0_Torgersen'])\n",
    "y = copy_df['species'].to_numpy().reshape(1, -1)[0] * 1\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=19)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "MLP_targ = Perceptron([3], [lambda x: round(min(Perceptron.relu(x), 2))], n_epochs=200, random_state=16, eta=0.0001)\n",
    "errors = MLP_targ.train(X_train, y_train, logging=False, activation=Perceptron.relu,\n",
    "                        random_weights=[-1, 1])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "build_errors(errors, MLP_targ, 'Многоклассивоая классификация')"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print_contour(MLP_targ, X, y, 0, 1, [2, 3, 4, 5, 6, 7], new_features, 'Многоклассивоая классификация')"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "acc(MLP_targ.predict(X_train), y_train)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "acc(MLP_targ.predict(X_test), y_test)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Метрики улучшились уже незначитель ну потому что уже некуда расти но видно что свое влияние остров оказывает"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Дополнительно глянем на 500 нейронах на первом слое"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "MLP_targ = Perceptron([500], [lambda x: round(min(Perceptron.relu(x), 2))], n_epochs=200, random_state=16, eta=0.0001)\n",
    "errors = MLP_targ.train(X_train, y_train, logging=False, activation=Perceptron.relu,\n",
    "                        random_weights=[-1, 1])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "build_errors(errors, MLP_targ, 'Многоклассовая классификация')"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print_contour(MLP_targ, X, y, 0, 1, [2, 3, 4, 5, 6, 7], new_features, 'Многоклассовая классификация 500 нейронов на первом слое')"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "acc(MLP_targ.predict(X_train), y_train)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "acc(MLP_targ.predict(X_test), y_test)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Глянули что если поставить больше слоев, видно что нейросеть как-то пытается разделить эти данные, и у нее неплохо получается метрика 0.97"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Делаем выводы"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Сходимость у персептрона неравномерная, обязательно данные приводить к одному виду и функцию активации нужно использовать relu чтобы сходилось лучше или другие ее подвиды.\n",
    "\n",
    "Также можно сказать что персептрон хоть и простая нейросеть но все равно очень мощно решает задачи регрессии и классификации даже в самом простом своем виде без обратного распространения ошибки, а математика проще чем в SVM или градиентном спуске, но при этом он универсален, однако за использование правила хебба приходится платить определенную цену в виде неравномерной сходимости и сильной зависимостью от порядка данных\n",
    "\n",
    "Так же стоит еще посмотреть на категориальные данные есть мысль что персептрон несильно зависит от их математического вида (матрица 0 и 1 либо вектор чисел) есть ощущение что с точки зрения персептрона можно добавить нейронов и он выдаст ту же точность.\n",
    "\n",
    "Также некоторые задания были не очень понятны потому мы их сделали на свое усмотрение например четвертое задание звучит будто сделайте 3 персептрона и 1 нейрон или как имелось в виду ведь мы уже написали персептрон со скрытыми слоями зачем отдельно обучать другой нейрон, можно же в рамках одного персептрона.\n",
    "\n",
    "Не очень понятно что такое характер обучения, такое нигде никогда не обсуждалось и дискуссия с одногруппниками ни к чему не привела\n",
    "\n",
    "Еще было много одинаковых заданий из-за чего пришлось помучаться если бы они были более объемные то можно было бы написать функцию универсальную а тут маленькие повторяющиеся из-за этого как-то неприятно\n",
    "\n",
    "В целом было очень интересная лабораторная мы справились с многоклассовой классификацией можно попробовать с числами сделать классификацию"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
