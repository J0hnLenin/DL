{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Лабораторная работа №4\n",
    "БЭКПРОПАГЕЙШН\n",
    "\n",
    "Выполнили студенты Зимин Андрей Валерьевич, Жилин Андрей Игроевич"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.f2py.auxfuncs import throw_error\n",
    "\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.metrics import recall_score as rec\n",
    "from sklearn.metrics import precision_score as pre\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import qrcode\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import string\n",
    "from typing import Callable, List, Union\n",
    "from numpy.typing import NDArray\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.metrics import recall_score as rec\n",
    "from sklearn.metrics import precision_score as pre\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Задание в классе. Предварительное исследование данных.\n",
    "\n",
    "1. Загрузить данные из файлов «vinequality-red.csv» и «vinequality-white.csv» об образцах красного и белого вина, соответственно.\n",
    "2. На основе загруженных данных формировать 3 датасета:\n",
    "Параметры и качество белого вина (12 признаков, 4898 образцов) по данным второго файла,\n",
    "Параметры и качество вина Vinho Verde (12 признаков, 6497 образцов), по данным обоих файлов.\n",
    "Параметры и качество вина Vinho Verde (13 признаков, 6497 образцов), по данным обоих файлов, введя бинарный признак для отличия красного и белого вина.\n",
    "Распечатать размерность и первые 5 строк каждого датасета.\n",
    "3. Построить гистограмму распределения значения признака «качество вина» по каждому датасету.\n",
    "4. Для каждого датасета вычислить матрицу парных корреляций всех признаков и построить её тепловую карту (по примеру на картинке).\n",
    "\n",
    "5. Заменить значения входных признаков каждого датасета их стандартизованными значениями, т.е. выполнить Z-стандартизацию по формуле\n",
    "\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Задание 1.1\n",
    "\n",
    "Загрузить данные из файлов «vinequality-red.csv» и «vinequality-white.csv» об образцах красного и белого вина, соответственно.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_redwine = pd.read_csv(\"./data/winequality-red.csv\", sep=\";\")\n",
    "df_redwine.head()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Задание 1.2\n",
    "На основе загруженных данных формировать 3 датасета:\n",
    "A. Параметры и качество белого вина (12 признаков, 4898 образцов) по данным второго файла,"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_whitewine = pd.read_csv(\"./data/winequality-white.csv\", sep=\";\") # A-датасет\n",
    "print(df_whitewine.info())\n",
    "df_whitewine.head()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "B. Параметры и качество вина Vinho Verde (12 признаков, 6497 образцов), по данным обоих файлов."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_redwhite = pd.concat([df_redwine, df_whitewine], ignore_index=True)\n",
    "print(df_redwhite.info())\n",
    "df_redwhite.head()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "temp_df_whitewine = df_whitewine.copy()\n",
    "temp_df_redwine = df_redwine.copy()\n",
    "temp_df_whitewine['is_red'] = pd.Series([False]*len(df_redwine), dtype=\"bool\")\n",
    "temp_df_redwine['is_white'] = pd.Series([False]*len(df_redwine), dtype=\"bool\")\n",
    "temp_df_whitewine['is_white'] = pd.Series([True]*len(df_redwine), dtype=\"bool\")\n",
    "temp_df_redwine['is_red'] = pd.Series([True]*len(df_redwine), dtype=\"bool\")\n",
    "\n",
    "temp_df_redwine.head()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Загрузили датасет. Действительно 7 признаков и 333 строки"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df = pd.concat([df_redwine, df_whitewine], ignore_index=True)\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "species            - категориальный признак  \n",
    "island             - категориальный признак  \n",
    "bill_length_mm     - числовой признак  \n",
    "bill_depth_mm      - числовой признак  \n",
    "flipper_length_mm  - числовой признак  \n",
    "body_mass_g        - числовой признак  \n",
    "sex                - бинарный признак   "
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Перед обучением нужно будет закодировать категориальные признаки one-hot encoding"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "df.describe()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Видим, что сильно выделяется признак массы тела, он на 2-3 порядка больше остальных признаков. Перед обучением было бы неплохо провести нормализацию"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "category_columns = ['species', 'island', 'sex']\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "#for i, category in enumerate(category_columns):\n",
    "#   ax[i].bar()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Perceptron:\n",
    "  def __init__(self, hidden_layers : List[int],\n",
    "               activations: List[Callable],\n",
    "               eta:Union[int, float] = 1,\n",
    "               n_epochs: int = 100,\n",
    "               random_weights=None,\n",
    "               random_state=None):\n",
    "    np.random.seed(random_state)\n",
    "    random.seed(random_state)\n",
    "    self.is_fitted = False\n",
    "    self.layers = []\n",
    "    self.epochs = n_epochs\n",
    "    self.eta = eta\n",
    "    self.errors = []\n",
    "    l = hidden_layers + [1]\n",
    "    for i in range(len(hidden_layers)):\n",
    "      self.layers.append(Layer((l[i]+1, l[i+1]), activations[i], i + 1, random_weights=random_weights))\n",
    "\n",
    "  @staticmethod\n",
    "  def relu(x):\n",
    "      return np.maximum(0, x)\n",
    "  @staticmethod\n",
    "  def step(x):\n",
    "      return (x >= 0).astype(np.float64)\n",
    "\n",
    "  @staticmethod\n",
    "  def sigmoid(x):\n",
    "    return np.where(x >= 0,\n",
    "                   1 / (1 + np.exp(-x)),\n",
    "                   np.exp(x) / (1 + np.exp(x)))\n",
    "\n",
    "  @staticmethod\n",
    "  def shuffle(X, y):\n",
    "    n = len(y)\n",
    "    a = [(random.random(), X[i, :], y[i]) for i in range(n)]\n",
    "    a.sort()\n",
    "    new_X = np.array([a[i][1] for i in range(n)])\n",
    "    new_y = np.array([a[i][2] for i in range(n)])\n",
    "    return new_X, new_y\n",
    "\n",
    "  @staticmethod\n",
    "  def get_grad(activation):\n",
    "      activation = activation.pyfunc\n",
    "      if activation == Perceptron.sigmoid:\n",
    "          s = Perceptron.sigmoid\n",
    "          return lambda x: s(x) * (1 - s(x))\n",
    "      return lambda x: (x >= 0).astype(np.int64)\n",
    "\n",
    "\n",
    "  def predict(self, train_sample: NDArray, logging: bool = False) -> NDArray:\n",
    "    result = np.zeros(train_sample.shape[0])\n",
    "    for i in range(train_sample.shape[0]):\n",
    "      x = train_sample[i, :]\n",
    "      for layer in self.layers:\n",
    "        x = np.append(x, values=[1]) # добавление свободного коэффициента\n",
    "        x = layer.forward(x, logging)\n",
    "\n",
    "      result[i] = x[0]\n",
    "      if logging:\n",
    "        print(result[i])\n",
    "    return result\n",
    "\n",
    "  def train(self, train_sample: NDArray,\n",
    "          train_ans: NDArray,\n",
    "          batch_size: int = 32,  # Размер пакета (можно менять)\n",
    "          logging=False,\n",
    "          activation=np.sign,\n",
    "          random_weights=None) -> list[float]:\n",
    "    if not self.is_fitted:\n",
    "        self.layers = [Layer((train_sample.shape[1]+1,\n",
    "                            self.layers[0].size[0]-1),\n",
    "                            activation,\n",
    "                            0,\n",
    "                            random_weights=random_weights)] + self.layers\n",
    "        self.is_fitted = True\n",
    "\n",
    "    n_samples = train_sample.shape[0]\n",
    "    for epoch in range(self.epochs):\n",
    "        train_sample, train_ans = Perceptron.shuffle(train_sample, train_ans)\n",
    "        error = 0\n",
    "\n",
    "        # Разбиваем данные на пакеты\n",
    "        for batch_start in range(0, n_samples, batch_size):\n",
    "            batch_end = min(batch_start + batch_size, n_samples)\n",
    "            batch_X = train_sample[batch_start:batch_end, :]\n",
    "            batch_y = train_ans[batch_start:batch_end]\n",
    "\n",
    "            # Инициализируем накопители градиентов для каждого слоя\n",
    "            weight_updates = [np.zeros_like(layer.w) for layer in self.layers]\n",
    "            batch_error = 0\n",
    "\n",
    "            # Обрабатываем каждый пример в пакете\n",
    "            for i in range(batch_X.shape[0]):\n",
    "                x = batch_X[i, :]\n",
    "                target = batch_y[i]\n",
    "\n",
    "                # Прямое распространение (forward pass)\n",
    "                activations = [x]\n",
    "                for layer in self.layers:\n",
    "                    x = np.append(x, values=[1])\n",
    "                    x = layer.forward(x, logging)\n",
    "                    activations.append(x)\n",
    "\n",
    "                predicted = x[0]\n",
    "                delta = target - predicted\n",
    "                batch_error += abs(delta)\n",
    "\n",
    "                # Обратное распространение (backward pass)\n",
    "                delta_next = delta\n",
    "                for layer_idx in range(len(self.layers)-1, -1, -1):\n",
    "                    layer = self.layers[layer_idx]\n",
    "                    layer_input = activations[layer_idx]\n",
    "                    delta_next, weight_update = layer.backprop(delta_next, layer_input, self.eta)\n",
    "                    weight_updates[layer_idx] += weight_update  # Накопление градиентов\n",
    "\n",
    "            # Усредняем градиенты и обновляем веса\n",
    "            for layer, update in zip(self.layers, weight_updates):\n",
    "                layer.w += (self.eta / batch_size) * update  # Усреднённое обновление\n",
    "\n",
    "            error += batch_error\n",
    "\n",
    "        self.errors.append(error)\n",
    "    return self.errors\n",
    "\n",
    "\n",
    "class Layer:\n",
    "  def __init__(self,\n",
    "               size: tuple[int, int],\n",
    "               activation: Callable,\n",
    "               index: int,\n",
    "               value: Union[int, float]=0,\n",
    "               random_weights=None):\n",
    "    self.size = size\n",
    "    self.w = np.full(size, value, dtype=np.float64)\n",
    "    if random_weights is not None:\n",
    "      self.w = np.random.uniform(random_weights[0], random_weights[1], self.size)\n",
    "    self.activation = np.vectorize(activation)\n",
    "    self.i = index\n",
    "    self.last_result = np.array([])\n",
    "    self.last_x = np.array([])\n",
    "    self.last_m = np.array([])\n",
    "\n",
    "  def backward(self, value) -> None:\n",
    "    if value > 0:\n",
    "      # надо увеличить те веса, где нет активации,\n",
    "      # но должна быть активация\n",
    "      d = (self.last_x>0)*value\n",
    "      d = np.repeat(np.array([d]).T, self.w.shape[1], axis=1)\n",
    "      self.w = self.w + d\n",
    "    if value < 0:\n",
    "      # надо уменьшить те веса,\n",
    "      # где активации быть не должно\n",
    "      d = (self.last_x>0)*value\n",
    "      d = np.repeat(np.array([d]).T, self.w.shape[1], axis=1)\n",
    "      self.w = self.w + d\n",
    "  def backprop(self, delta_prev, layer_input, eta):\n",
    "    # Получаем взвешенную сумму (последний расчёт в forward)\n",
    "    m = self.last_m\n",
    "\n",
    "    # Вычисляем производную активационной функции\n",
    "    grad = Perceptron.get_grad(self.activation)(m)\n",
    "\n",
    "    # delta для текущего слоя = delta_prev * производная активации\n",
    "    delta = delta_prev * grad\n",
    "\n",
    "    # Добавляем bias-единицу к входному вектору (если её ещё нет)\n",
    "    layer_input_with_bias = np.append(layer_input, 1)\n",
    "\n",
    "    # Возвращаем ошибку для предыдущего слоя (без учёта bias-весов)\n",
    "    delta_next = delta @ self.w[:-1].T\n",
    "\n",
    "    # Возвращаем градиент для накопления (без обновления весов)\n",
    "    weight_update = np.outer(layer_input_with_bias, delta)\n",
    "\n",
    "    return delta_next, weight_update\n",
    "\n",
    "  def forward(self, x, logging) -> NDArray:\n",
    "    if logging:\n",
    "      print(f\"Слой №{self.i+1}\")\n",
    "      print(f\"Сенсоры  : {x}\")\n",
    "      print(f\"Размер: {self.size}\")\n",
    "\n",
    "    m = np.dot(x, self.w)\n",
    "    result = self.activation(m)\n",
    "    self.last_result = result\n",
    "    self.last_x = x\n",
    "    self.last_m = m\n",
    "    if logging:\n",
    "      print(f\"Сумматор : {m}\")\n",
    "      print(f\"Активация: {result}\")\n",
    "      print(f\"Результат размера {result.shape}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "def count_metrics(predicted : NDArray[bool], real: NDArray[bool], label='') -> None:\n",
    "    print(f'{label}: ')\n",
    "    print('Accuracy: ', acc(predicted, real))\n",
    "    print('Recall: ', rec(predicted, real))\n",
    "    print('Precision: ', pre(predicted, real))\n",
    "\n",
    "\n",
    "def get_features(data, target, target_name, features) -> (NDArray, NDArray):\n",
    "\n",
    "    data = data[features + [target]]\n",
    "    data.loc[:, target] = (data[target] == target_name)\n",
    "    data_y = data[[target]].to_numpy().reshape(1, -1)[0] * 1\n",
    "    data_x = data[features].to_numpy()\n",
    "\n",
    "    return data_x, data_y\n",
    "\n",
    "\n",
    "def build_errors(errors: list[float], perceptron: Perceptron) -> None:\n",
    "    ax = plt.figure().gca()\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    plt.plot(list(range(len(errors))), errors, marker='o', linestyle='dashed')\n",
    "\n",
    "    plt.xlabel(\"Эпохи\")\n",
    "    plt.ylabel(\"Количество ошибок за эпоху\")\n",
    "    plt.title(\"Обучение нейросети\\nбинарной классификации на числовых признаках\")\n",
    "    print(\"Размерность слоёв: \", *[i.size for i in  perceptron.layers])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def print_contour(model, X, y, main_1=0, main_2=1, supp=None, columns_num=None):\n",
    "    # 1. Генерируем сетку для 2-х выбранных признаков\n",
    "    if supp is None:\n",
    "        supp = [2, 3]\n",
    "    if columns_num is None:\n",
    "        columns_num = [''] * 2\n",
    "    x_min, x_max = X[:, main_1].min() - 1, X[:, main_1].max() + 1\n",
    "    y_min, y_max = X[:, main_2].min() - 1, X[:, main_2].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "    # 2. Создаём массив точек в 4-х мерном пространстве, но только для выбранных 2-х признаков\n",
    "    mean_vals = np.mean(X, axis=0)  # Средние значения для всех 4-х признаков\n",
    "    fixed_features = mean_vals[supp]  # Средние значения для 3-го и 4-го признаков\n",
    "\n",
    "    grid_points_4d = np.zeros((xx.ravel().shape[0], 2+len(supp)))\n",
    "    grid_points_4d[:, [main_1, main_2]] = np.column_stack((xx.ravel(), yy.ravel()))  # 2 выбранных признака\n",
    "    grid_points_4d[:, [supp]] = fixed_features  # Остальные 2 признака - средние значения\n",
    "\n",
    "    # 3. Предсказываем классы для сеточных точек в 4-х мерном пространстве\n",
    "    Z = model.predict(grid_points_4d)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # 4. Визуализация\n",
    "    plt.contourf(xx, yy, Z, alpha=0.8, cmap='coolwarm')\n",
    "    plt.contour(xx, yy, Z, colors=['k', 'k', 'k'], linestyles=['--', '-', '--'], linewidths=[1, 2, 1])\n",
    "\n",
    "    # Отображаем точки данных\n",
    "    plt.scatter(X[:, main_1], X[:, main_2], c=y, cmap='coolwarm', edgecolor='k')\n",
    "    plt.xlabel(columns_num[main_1])\n",
    "    plt.ylabel(columns_num[main_2])\n",
    "    plt.title('Проекция линий уровня персептрона на 2D')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
